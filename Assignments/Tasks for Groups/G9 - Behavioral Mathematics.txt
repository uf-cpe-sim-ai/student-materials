Humans do not always act rationally - but just as importantly, the agents humans develop do not always act rationally. This must be a consideration in the development of AI agents, as discussed in our videos.

Consider this perspective in Robocode. Work on answering these questions first:
1) What decision making models do you think are likely to be deployed by opponents?
2) What sorts of heuristics do yo expect them to employ?
3) What would they predict your agents' behaviors to be?

Now consider how your agents can use this information. Can you mislead other agents to take advantage? How does this information impact your current strategy?